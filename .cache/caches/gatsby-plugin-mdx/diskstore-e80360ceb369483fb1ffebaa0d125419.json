{"expireTime":9007200852747632000,"key":"gatsby-plugin-mdx-entire-payload-591351e596572657046661b79568bfcd-","val":{"mdast":{"type":"root","children":[{"type":"paragraph","children":[{"type":"text","value":"Following on from my article about the ","position":{"start":{"line":2,"column":1,"offset":2},"end":{"line":2,"column":40,"offset":41},"indent":[]}},{"type":"link","title":null,"url":"https://richardhaines.dev/use-cloudinary-hooks-use-search/","children":[{"type":"text","value":"use-cloudinary - useSearch hook","position":{"start":{"line":2,"column":41,"offset":42},"end":{"line":2,"column":72,"offset":73},"indent":[]}}],"position":{"start":{"line":2,"column":40,"offset":41},"end":{"line":2,"column":133,"offset":134},"indent":[]}},{"type":"text","value":", this time we'll be streamlining our code and diving into some of whats possible with when manipulating our cloudinary folders.","position":{"start":{"line":2,"column":133,"offset":134},"end":{"line":2,"column":261,"offset":262},"indent":[]}}],"position":{"start":{"line":2,"column":1,"offset":2},"end":{"line":2,"column":261,"offset":262},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"If we recount what we did last time:","position":{"start":{"line":4,"column":1,"offset":266},"end":{"line":4,"column":37,"offset":302},"indent":[]}}],"position":{"start":{"line":4,"column":1,"offset":266},"end":{"line":4,"column":37,"offset":302},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"A user could load their 3 previously saved images on the click of a button","position":{"start":{"line":6,"column":3,"offset":308},"end":{"line":6,"column":77,"offset":382},"indent":[]}}],"position":{"start":{"line":6,"column":3,"offset":308},"end":{"line":6,"column":77,"offset":382},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":306},"end":{"line":6,"column":77,"offset":382},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"The search expression told cloudinary that our type of media was image and that we wanted an exact match on the folders","position":{"start":{"line":7,"column":3,"offset":386},"end":{"line":7,"column":122,"offset":505},"indent":[]}}],"position":{"start":{"line":7,"column":3,"offset":386},"end":{"line":7,"column":122,"offset":505},"indent":[]}}],"position":{"start":{"line":7,"column":1,"offset":384},"end":{"line":7,"column":122,"offset":505},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Our serverless function set the mex results returned, in our case 3","position":{"start":{"line":8,"column":3,"offset":509},"end":{"line":8,"column":70,"offset":576},"indent":[]}}],"position":{"start":{"line":8,"column":3,"offset":509},"end":{"line":8,"column":70,"offset":576},"indent":[]}}],"position":{"start":{"line":8,"column":1,"offset":507},"end":{"line":8,"column":70,"offset":576},"indent":[]}}],"position":{"start":{"line":6,"column":1,"offset":306},"end":{"line":8,"column":70,"offset":576},"indent":[1,1]}},{"type":"paragraph","children":[{"type":"text","value":"This is a great, simple solution, but there is one problem. If we are stating that our user can only load their last 3 images but at the same time allowing them to save as many images as they like then we put ourselves and our cloudinary accounts credits at risk of being abused. This of course would be no fault of the users, we are the ones setting up the rules by which they should follow. No, alas it is our fault (well mine.... cough cough). Lets refactor a wee bit and see what we can do to make this process better.","position":{"start":{"line":10,"column":1,"offset":580},"end":{"line":10,"column":523,"offset":1102},"indent":[]}}],"position":{"start":{"line":10,"column":1,"offset":580},"end":{"line":10,"column":523,"offset":1102},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Our search function will remain unchanged, our function will still search for an exact folder based on our users name. Our upload function however could do with some work.","position":{"start":{"line":12,"column":1,"offset":1106},"end":{"line":12,"column":172,"offset":1277},"indent":[]}}],"position":{"start":{"line":12,"column":1,"offset":1106},"end":{"line":12,"column":172,"offset":1277},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"The previous upload serverless function","position":{"start":{"line":14,"column":4,"offset":1284},"end":{"line":14,"column":43,"offset":1323},"indent":[]}}],"position":{"start":{"line":14,"column":1,"offset":1281},"end":{"line":14,"column":43,"offset":1323},"indent":[]}},{"type":"code","lang":"js","meta":null,"value":"const cloudinary = require(\"cloudinary\").v2;\nconst dotenv = require(\"dotenv\");\ndotenv.config();\n\ncloudinary.config({\n  cloud_name: process.env.CLOUDINARY_NAME,\n  api_key: process.env.CLOUDINARY_API_KEY,\n  api_secret: process.env.CLOUDINARY_API_SECRET\n});\n\nexports.handler = async event => {\n  const { file } = JSON.parse(event.body);\n  const res = await cloudinary.uploader.upload(file, { ...JSON.parse(event.body) });\n  return {\n    statusCode: 200,\n    body: JSON.stringify(res)\n  };\n};","position":{"start":{"line":16,"column":1,"offset":1327},"end":{"line":35,"column":4,"offset":1844},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"The function takes and parses the passed in event, from which our file to upload is destructured and added to the cloudinary uploader function along with the rest of the image transformations. Cool.","position":{"start":{"line":37,"column":1,"offset":1848},"end":{"line":37,"column":199,"offset":2046},"indent":[]}}],"position":{"start":{"line":37,"column":1,"offset":1848},"end":{"line":37,"column":199,"offset":2046},"indent":[]}},{"type":"heading","depth":2,"children":[{"type":"text","value":"The super duper upload serverless function","position":{"start":{"line":39,"column":4,"offset":2053},"end":{"line":39,"column":46,"offset":2095},"indent":[]}}],"position":{"start":{"line":39,"column":1,"offset":2050},"end":{"line":39,"column":46,"offset":2095},"indent":[]}},{"type":"paragraph","children":[{"type":"text","value":"Brace yourselves.....here it comes....","position":{"start":{"line":41,"column":1,"offset":2099},"end":{"line":41,"column":39,"offset":2137},"indent":[]}}],"position":{"start":{"line":41,"column":1,"offset":2099},"end":{"line":41,"column":39,"offset":2137},"indent":[]}},{"type":"code","lang":"js","meta":null,"value":"const cloudinary = require(\"cloudinary\").v2;\nconst dotenv = require(\"dotenv\");\ndotenv.config();\n\ncloudinary.config({\n  cloud_name: process.env.CLOUDINARY_NAME,\n  api_key: process.env.CLOUDINARY_API_KEY,\n  api_secret: process.env.CLOUDINARY_API_SECRET\n});\n\n// Upload an image with a max of 3 images in a folder\nexports.handler = async event => {\n  const { file } = JSON.parse(event.body);\n  const body = JSON.parse(event.body);\n  // extract the folder from the public_id\n  const folder = body.public_id.split(\"/\")[0];\n\n  // get the images of the folder and sort them by the uploaded date\n  const searchRes = await cloudinary.search\n    .expression(folder)\n    .sort_by(\"uploaded_at\")\n    .execute()\n    .then(searchResult => searchResult);\n\n  // if the folder contains 3 images then delete the oldest one\n  if (searchRes.resources.length === 3) {\n    await cloudinary.uploader.destroy(searchRes.resources[searchRes.resources.length - 1].public_id);\n  }\n\n  // upload our new image to the folder\n  const res = await cloudinary.uploader.upload(file, { ...JSON.parse(event.body) });\n  return {\n    statusCode: 200,\n    body: JSON.stringify(res)\n  };\n};","position":{"start":{"line":43,"column":1,"offset":2141},"end":{"line":80,"column":4,"offset":3335},"indent":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"We'll go through this step by step to understand whats going on.","position":{"start":{"line":82,"column":1,"offset":3339},"end":{"line":82,"column":65,"offset":3403},"indent":[]}}],"position":{"start":{"line":82,"column":1,"offset":3339},"end":{"line":82,"column":65,"offset":3403},"indent":[]}},{"type":"list","ordered":false,"start":null,"spread":false,"children":[{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"As with all our serverless functions it takes an event. We parse and destructure the file that we want to upload and parse the body. We could do this in one but I like to split it out so its easy to read.","position":{"start":{"line":84,"column":3,"offset":3409},"end":{"line":84,"column":207,"offset":3613},"indent":[]}}],"position":{"start":{"line":84,"column":3,"offset":3409},"end":{"line":84,"column":207,"offset":3613},"indent":[]}}],"position":{"start":{"line":84,"column":1,"offset":3407},"end":{"line":84,"column":207,"offset":3613},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"We extract the folder name from the files public_id, grabbing anything before the forward slash.","position":{"start":{"line":85,"column":3,"offset":3617},"end":{"line":85,"column":99,"offset":3713},"indent":[]}}],"position":{"start":{"line":85,"column":3,"offset":3617},"end":{"line":85,"column":99,"offset":3713},"indent":[]}}],"position":{"start":{"line":85,"column":1,"offset":3615},"end":{"line":85,"column":99,"offset":3713},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"We run our cloudinary search function and pass our folder as the expression to search for.","position":{"start":{"line":86,"column":3,"offset":3717},"end":{"line":86,"column":93,"offset":3807},"indent":[]}}],"position":{"start":{"line":86,"column":3,"offset":3717},"end":{"line":86,"column":93,"offset":3807},"indent":[]}}],"position":{"start":{"line":86,"column":1,"offset":3715},"end":{"line":86,"column":93,"offset":3807},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"We sort the results by their uploaded_at date. This will give us the latest uploads first.","position":{"start":{"line":87,"column":3,"offset":3811},"end":{"line":87,"column":93,"offset":3901},"indent":[]}}],"position":{"start":{"line":87,"column":3,"offset":3811},"end":{"line":87,"column":93,"offset":3901},"indent":[]}}],"position":{"start":{"line":87,"column":1,"offset":3809},"end":{"line":87,"column":93,"offset":3901},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Notice that we have not included a max_results in this search. This means that we will get back all of the images in the folder.","position":{"start":{"line":88,"column":3,"offset":3905},"end":{"line":88,"column":131,"offset":4033},"indent":[]}}],"position":{"start":{"line":88,"column":3,"offset":3905},"end":{"line":88,"column":131,"offset":4033},"indent":[]}}],"position":{"start":{"line":88,"column":1,"offset":3903},"end":{"line":88,"column":131,"offset":4033},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"We then check if the returned arrays length is equal to 3, as we only want to have 3 images max in our folder. If their are 3 images we want to remove the oldest one as we will soon be uploading a new image to the folder.","position":{"start":{"line":89,"column":3,"offset":4037},"end":{"line":89,"column":224,"offset":4258},"indent":[]}}],"position":{"start":{"line":89,"column":3,"offset":4037},"end":{"line":89,"column":224,"offset":4258},"indent":[]}}],"position":{"start":{"line":89,"column":1,"offset":4035},"end":{"line":89,"column":224,"offset":4258},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Cloudinary has a handy destroy function which along with an optional callback accepts the public_id of the image you wish to remove.","position":{"start":{"line":90,"column":3,"offset":4262},"end":{"line":90,"column":135,"offset":4394},"indent":[]}}],"position":{"start":{"line":90,"column":3,"offset":4262},"end":{"line":90,"column":135,"offset":4394},"indent":[]}}],"position":{"start":{"line":90,"column":1,"offset":4260},"end":{"line":90,"column":135,"offset":4394},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"We pass in the last index of the search results array, as that will be our oldest entry.","position":{"start":{"line":91,"column":3,"offset":4398},"end":{"line":91,"column":91,"offset":4486},"indent":[]}}],"position":{"start":{"line":91,"column":3,"offset":4398},"end":{"line":91,"column":91,"offset":4486},"indent":[]}}],"position":{"start":{"line":91,"column":1,"offset":4396},"end":{"line":91,"column":91,"offset":4486},"indent":[]}},{"type":"listItem","spread":false,"checked":null,"children":[{"type":"paragraph","children":[{"type":"text","value":"Finally we upload our new image to the same folder and return that wonderful 200 and the results!","position":{"start":{"line":92,"column":3,"offset":4490},"end":{"line":92,"column":100,"offset":4587},"indent":[]}}],"position":{"start":{"line":92,"column":3,"offset":4490},"end":{"line":92,"column":100,"offset":4587},"indent":[]}}],"position":{"start":{"line":92,"column":1,"offset":4488},"end":{"line":92,"column":100,"offset":4587},"indent":[]}}],"position":{"start":{"line":84,"column":1,"offset":3407},"end":{"line":92,"column":100,"offset":4587},"indent":[1,1,1,1,1,1,1,1]}},{"type":"paragraph","children":[{"type":"text","value":"Now we have ensured that our cloudinary credits are safe from those pesky image uploaders. Our folder is set to only accept 3 images. Of course we could choose any number we like. In an up coming tutorial series I'll walk you through creating an authenticated photo album library which will extensively use this hooks library and cloudinary.","position":{"start":{"line":94,"column":1,"offset":4591},"end":{"line":94,"column":342,"offset":4932},"indent":[]}}],"position":{"start":{"line":94,"column":1,"offset":4591},"end":{"line":94,"column":342,"offset":4932},"indent":[]}},{"type":"export","value":"export const _frontmatter = {\"title\":\"use-cloudinary - Controlling our folders\",\"date\":\"2020-08-19T00:00:00.000Z\",\"published\":true,\"category\":\"First Look\",\"author\":\"Richard Haines\",\"keywords\":[\"cloudinary\",\"use-cloudinary\",\"hooks\"],\"pin\":false}","position":{"start":{"line":97,"column":1,"offset":4936},"end":{"line":97,"column":245,"offset":5180},"indent":[]}}],"position":{"start":{"line":1,"column":1,"offset":0},"end":{"line":97,"column":245,"offset":5180}}},"scopeImports":["import React from 'react'"],"scopeIdentifiers":["React"],"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"use-cloudinary - Controlling our folders\",\n  \"date\": \"2020-08-19T00:00:00.000Z\",\n  \"published\": true,\n  \"category\": \"First Look\",\n  \"author\": \"Richard Haines\",\n  \"keywords\": [\"cloudinary\", \"use-cloudinary\", \"hooks\"],\n  \"pin\": false\n};\n\nvar makeShortcode = function makeShortcode(name) {\n  return function MDXDefaultShortcode(props) {\n    console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n    return mdx(\"div\", props);\n  };\n};\n\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Following on from my article about the \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://richardhaines.dev/use-cloudinary-hooks-use-search/\"\n  }), \"use-cloudinary - useSearch hook\"), \", this time we'll be streamlining our code and diving into some of whats possible with when manipulating our cloudinary folders.\"), mdx(\"p\", null, \"If we recount what we did last time:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A user could load their 3 previously saved images on the click of a button\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"The search expression told cloudinary that our type of media was image and that we wanted an exact match on the folders\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Our serverless function set the mex results returned, in our case 3\")), mdx(\"p\", null, \"This is a great, simple solution, but there is one problem. If we are stating that our user can only load their last 3 images but at the same time allowing them to save as many images as they like then we put ourselves and our cloudinary accounts credits at risk of being abused. This of course would be no fault of the users, we are the ones setting up the rules by which they should follow. No, alas it is our fault (well mine.... cough cough). Lets refactor a wee bit and see what we can do to make this process better.\"), mdx(\"p\", null, \"Our search function will remain unchanged, our function will still search for an exact folder based on our users name. Our upload function however could do with some work.\"), mdx(\"h2\", {\n    \"id\": \"the-previous-upload-serverless-function\"\n  }, \"The previous upload serverless function\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"const cloudinary = require(\\\"cloudinary\\\").v2;\\nconst dotenv = require(\\\"dotenv\\\");\\ndotenv.config();\\n\\ncloudinary.config({\\n  cloud_name: process.env.CLOUDINARY_NAME,\\n  api_key: process.env.CLOUDINARY_API_KEY,\\n  api_secret: process.env.CLOUDINARY_API_SECRET\\n});\\n\\nexports.handler = async event => {\\n  const { file } = JSON.parse(event.body);\\n  const res = await cloudinary.uploader.upload(file, { ...JSON.parse(event.body) });\\n  return {\\n    statusCode: 200,\\n    body: JSON.stringify(res)\\n  };\\n};\\n\")), mdx(\"p\", null, \"The function takes and parses the passed in event, from which our file to upload is destructured and added to the cloudinary uploader function along with the rest of the image transformations. Cool.\"), mdx(\"h2\", {\n    \"id\": \"the-super-duper-upload-serverless-function\"\n  }, \"The super duper upload serverless function\"), mdx(\"p\", null, \"Brace yourselves.....here it comes....\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {\n    \"className\": \"language-js\"\n  }), \"const cloudinary = require(\\\"cloudinary\\\").v2;\\nconst dotenv = require(\\\"dotenv\\\");\\ndotenv.config();\\n\\ncloudinary.config({\\n  cloud_name: process.env.CLOUDINARY_NAME,\\n  api_key: process.env.CLOUDINARY_API_KEY,\\n  api_secret: process.env.CLOUDINARY_API_SECRET\\n});\\n\\n// Upload an image with a max of 3 images in a folder\\nexports.handler = async event => {\\n  const { file } = JSON.parse(event.body);\\n  const body = JSON.parse(event.body);\\n  // extract the folder from the public_id\\n  const folder = body.public_id.split(\\\"/\\\")[0];\\n\\n  // get the images of the folder and sort them by the uploaded date\\n  const searchRes = await cloudinary.search\\n    .expression(folder)\\n    .sort_by(\\\"uploaded_at\\\")\\n    .execute()\\n    .then(searchResult => searchResult);\\n\\n  // if the folder contains 3 images then delete the oldest one\\n  if (searchRes.resources.length === 3) {\\n    await cloudinary.uploader.destroy(searchRes.resources[searchRes.resources.length - 1].public_id);\\n  }\\n\\n  // upload our new image to the folder\\n  const res = await cloudinary.uploader.upload(file, { ...JSON.parse(event.body) });\\n  return {\\n    statusCode: 200,\\n    body: JSON.stringify(res)\\n  };\\n};\\n\")), mdx(\"p\", null, \"We'll go through this step by step to understand whats going on.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"As with all our serverless functions it takes an event. We parse and destructure the file that we want to upload and parse the body. We could do this in one but I like to split it out so its easy to read.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"We extract the folder name from the files public_id, grabbing anything before the forward slash.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"We run our cloudinary search function and pass our folder as the expression to search for.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"We sort the results by their uploaded_at date. This will give us the latest uploads first.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Notice that we have not included a max_results in this search. This means that we will get back all of the images in the folder.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"We then check if the returned arrays length is equal to 3, as we only want to have 3 images max in our folder. If their are 3 images we want to remove the oldest one as we will soon be uploading a new image to the folder.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Cloudinary has a handy destroy function which along with an optional callback accepts the public_id of the image you wish to remove.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"We pass in the last index of the search results array, as that will be our oldest entry.\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Finally we upload our new image to the same folder and return that wonderful 200 and the results!\")), mdx(\"p\", null, \"Now we have ensured that our cloudinary credits are safe from those pesky image uploaders. Our folder is set to only accept 3 images. Of course we could choose any number we like. In an up coming tutorial series I'll walk you through creating an authenticated photo album library which will extensively use this hooks library and cloudinary.\"));\n}\n;\nMDXContent.isMDXComponent = true;","rawMDXOutput":"/* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\n\nexport const _frontmatter = {\n  \"title\": \"use-cloudinary - Controlling our folders\",\n  \"date\": \"2020-08-19T00:00:00.000Z\",\n  \"published\": true,\n  \"category\": \"First Look\",\n  \"author\": \"Richard Haines\",\n  \"keywords\": [\"cloudinary\", \"use-cloudinary\", \"hooks\"],\n  \"pin\": false\n};\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\")\n  return <div {...props}/>\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = \"wrapper\"\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n    <p>{`Following on from my article about the `}<a parentName=\"p\" {...{\n        \"href\": \"https://richardhaines.dev/use-cloudinary-hooks-use-search/\"\n      }}>{`use-cloudinary - useSearch hook`}</a>{`, this time we'll be streamlining our code and diving into some of whats possible with when manipulating our cloudinary folders.`}</p>\n    <p>{`If we recount what we did last time:`}</p>\n    <ul>\n      <li parentName=\"ul\">{`A user could load their 3 previously saved images on the click of a button`}</li>\n      <li parentName=\"ul\">{`The search expression told cloudinary that our type of media was image and that we wanted an exact match on the folders`}</li>\n      <li parentName=\"ul\">{`Our serverless function set the mex results returned, in our case 3`}</li>\n    </ul>\n    <p>{`This is a great, simple solution, but there is one problem. If we are stating that our user can only load their last 3 images but at the same time allowing them to save as many images as they like then we put ourselves and our cloudinary accounts credits at risk of being abused. This of course would be no fault of the users, we are the ones setting up the rules by which they should follow. No, alas it is our fault (well mine.... cough cough). Lets refactor a wee bit and see what we can do to make this process better.`}</p>\n    <p>{`Our search function will remain unchanged, our function will still search for an exact folder based on our users name. Our upload function however could do with some work.`}</p>\n    <h2 {...{\n      \"id\": \"the-previous-upload-serverless-function\"\n    }}>{`The previous upload serverless function`}</h2>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-js\"\n      }}>{`const cloudinary = require(\"cloudinary\").v2;\nconst dotenv = require(\"dotenv\");\ndotenv.config();\n\ncloudinary.config({\n  cloud_name: process.env.CLOUDINARY_NAME,\n  api_key: process.env.CLOUDINARY_API_KEY,\n  api_secret: process.env.CLOUDINARY_API_SECRET\n});\n\nexports.handler = async event => {\n  const { file } = JSON.parse(event.body);\n  const res = await cloudinary.uploader.upload(file, { ...JSON.parse(event.body) });\n  return {\n    statusCode: 200,\n    body: JSON.stringify(res)\n  };\n};\n`}</code></pre>\n    <p>{`The function takes and parses the passed in event, from which our file to upload is destructured and added to the cloudinary uploader function along with the rest of the image transformations. Cool.`}</p>\n    <h2 {...{\n      \"id\": \"the-super-duper-upload-serverless-function\"\n    }}>{`The super duper upload serverless function`}</h2>\n    <p>{`Brace yourselves.....here it comes....`}</p>\n    <pre><code parentName=\"pre\" {...{\n        \"className\": \"language-js\"\n      }}>{`const cloudinary = require(\"cloudinary\").v2;\nconst dotenv = require(\"dotenv\");\ndotenv.config();\n\ncloudinary.config({\n  cloud_name: process.env.CLOUDINARY_NAME,\n  api_key: process.env.CLOUDINARY_API_KEY,\n  api_secret: process.env.CLOUDINARY_API_SECRET\n});\n\n// Upload an image with a max of 3 images in a folder\nexports.handler = async event => {\n  const { file } = JSON.parse(event.body);\n  const body = JSON.parse(event.body);\n  // extract the folder from the public_id\n  const folder = body.public_id.split(\"/\")[0];\n\n  // get the images of the folder and sort them by the uploaded date\n  const searchRes = await cloudinary.search\n    .expression(folder)\n    .sort_by(\"uploaded_at\")\n    .execute()\n    .then(searchResult => searchResult);\n\n  // if the folder contains 3 images then delete the oldest one\n  if (searchRes.resources.length === 3) {\n    await cloudinary.uploader.destroy(searchRes.resources[searchRes.resources.length - 1].public_id);\n  }\n\n  // upload our new image to the folder\n  const res = await cloudinary.uploader.upload(file, { ...JSON.parse(event.body) });\n  return {\n    statusCode: 200,\n    body: JSON.stringify(res)\n  };\n};\n`}</code></pre>\n    <p>{`We'll go through this step by step to understand whats going on.`}</p>\n    <ul>\n      <li parentName=\"ul\">{`As with all our serverless functions it takes an event. We parse and destructure the file that we want to upload and parse the body. We could do this in one but I like to split it out so its easy to read.`}</li>\n      <li parentName=\"ul\">{`We extract the folder name from the files public_id, grabbing anything before the forward slash.`}</li>\n      <li parentName=\"ul\">{`We run our cloudinary search function and pass our folder as the expression to search for.`}</li>\n      <li parentName=\"ul\">{`We sort the results by their uploaded_at date. This will give us the latest uploads first.`}</li>\n      <li parentName=\"ul\">{`Notice that we have not included a max_results in this search. This means that we will get back all of the images in the folder.`}</li>\n      <li parentName=\"ul\">{`We then check if the returned arrays length is equal to 3, as we only want to have 3 images max in our folder. If their are 3 images we want to remove the oldest one as we will soon be uploading a new image to the folder.`}</li>\n      <li parentName=\"ul\">{`Cloudinary has a handy destroy function which along with an optional callback accepts the public_id of the image you wish to remove.`}</li>\n      <li parentName=\"ul\">{`We pass in the last index of the search results array, as that will be our oldest entry.`}</li>\n      <li parentName=\"ul\">{`Finally we upload our new image to the same folder and return that wonderful 200 and the results!`}</li>\n    </ul>\n    <p>{`Now we have ensured that our cloudinary credits are safe from those pesky image uploaders. Our folder is set to only accept 3 images. Of course we could choose any number we like. In an up coming tutorial series I'll walk you through creating an authenticated photo album library which will extensively use this hooks library and cloudinary.`}</p>\n\n    </MDXLayout>;\n}\n\n;\nMDXContent.isMDXComponent = true;"}}